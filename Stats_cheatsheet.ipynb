{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stats/Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Khan Academy playlist notes\n",
    "\n",
    "The playlist [here](https://www.youtube.com/watch?v=uhxtUt_-GyM&list=PLGcvh64d5a4HfGkm8O4SIqbrS5HFaaM3B) covers a wide range of topics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important identities:\n",
    "\n",
    "- Variance = Standard Deviation Squared\n",
    "\n",
    "- Sample Variance = Population Variance times N/(N-1). This last term is Bessel's correction and makes the sample variance an unbiased estimator of the population variance\n",
    "\\begin{align}\n",
    "\\sigma^2_{\\text{sample}} = \\frac{1}{N_{\\text{sample}}-1}\\sum_{i=1}^{N_{sample}}(x_i - \\bar{x})^2,\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "- Variance of the sampling distribution of the sample mean = Variance of original population divided by sample size. **This is not the sample variance of the bullet above, this is the variance of the sample mean distribution for a given sample size**.\n",
    "\n",
    "\\begin{align}\n",
    "\\sigma^2_{\\text{sample}} = \\frac{\\sigma^2_{\\text{population}}}{N},\n",
    "\\end{align}\n",
    "where N = sample size.\n",
    "\n",
    "In terms of the standard deviation:\n",
    "\\begin{align}\n",
    "\\sigma_{\\text{sample}} = \\frac{\\sigma_{\\text{population}}}{\\sqrt{N}},\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Central Limit Theorem\n",
    "In probability theory, the central limit theorem (CLT) establishes that, in some situations, when independent random variables are added, their properly normalized sum tends toward a normal distribution (informally a \"bell curve\") even if the original variables themselves are not normally distributed. The theorem is a key (\"central\") concept in probability theory because it implies that probabilistic and statistical methods that work for normal distributions can be applicable to many problems involving other types of distributions. \n",
    "\n",
    "In other words, suppose that a sample is obtained containing a large number of observations, each observation being randomly generated in a way that does not depend on the values of the other observations, and that the arithmetic average of the observed values is computed. If this procedure is performed many times, the central limit theorem says that the distribution of the average will be closely approximated by a normal distribution. \n",
    "\n",
    "A simple example of this is that if one flips a coin many times the probability of getting a given number of heads in a series of flips will approach a normal curve, with mean equal to half the total number of flips in each series. (In the limit of an infinite number of flips, it will equal a normal curve.) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binomial Distribution\n",
    "\n",
    "A binomial distribution will tend to a normal distribution at the limit of large N. The assumptions of a binomial distribution are \n",
    "- There are two types of outomes\n",
    "- All events are independent\n",
    "- Probability of success (p) is same for all events (all coin throws)\n",
    "\n",
    "A good rule of thumb for when it's ok to use a binomial is when N * p > 5, where N is the number of users or size of your population and p is a probability (use 1-p if p > 0.5). Thus, for a CTP = 0.1, N=50 would be the threshold for the normal approximation to be \"good\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bernoulli Distribution\n",
    "\n",
    "Useful for binary outcomes in categorical distributions. For example, flip an unfair coint with heads probability = 0.7:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y = [0.7, 0.3]\n",
    "plt.bar(x=[0,1], height=Y, ); \n",
    "plt.xticks([0, 1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let *p* be the probability of the positive outcome, then we have \n",
    "\n",
    "- Mean $\\mu_x = p$ \n",
    "- Variance $\\sigma^2 = pq$ \n",
    "- Standard deviation $\\sigma = \\sqrt{pq}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Type-I error: A Type I error occurs when the null hypothesis is true (in other words, there really is no effect), but you reject the null hypothesis. \n",
    "### Type-I error is a FALSE POSITIVE (FP) error. The FP rate or probability is referred to as $\\alpha$, and is often chosen to be around 5%.\n",
    "### A good mnemonic is that type-I error is the one you MUST avoid in particle physics. NEVER declare a new particle if it is not there.\n",
    "\n",
    "\n",
    "<br><br>\n",
    "## Type-II error: A Type II error occurs when the alternative hypothesis is correct, but you fail to reject the null hypothesis (in other words, there really is an effect, but you failed to detect it).\n",
    "### - Type-II error is a FALSE NEGATIVE (FN) error. The FN rate or probability is referred to as $\\beta$, and is often chosen to be around 20%.\n",
    "### - Power = 1-$\\beta$. Power is the probability of rejecting the null hypothesis if the alternative hypothesis is the ground truth. Typical power values are 80%, as mentioned above.\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## p-value\n",
    "\n",
    "Integral of the CDF in the range that gives an equal or more extreme value of the test-statistic. For $\\alpha=0.05$, Z-score for two-tailed test is 1.96."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## t-test\n",
    "\n",
    "**Definition:** A t-test’s statistical significance indicates whether or not the difference between two groups’ averages most likely reflects a “real” difference in the population from which the groups were sampled.\n",
    "\n",
    "**Example:** Let’s say you’re interested in whether the average New Yorker spends more than the average Kansan per month on movies.\n",
    "\n",
    "![Example_ttest](img/ttest.png)\n",
    "\n",
    "You ask a sample of 3 people from each state about their movie spending. You might observe a difference in those averages (like 14USD for the average Kansan and 18USD for the average New Yorker). But that difference is not statistically significant; it could easily just be random luck of which 3 people you randomly sampled that makes one group appear to spend more money than the other. If instead you ask 300 New Yorkers and 300 Kansans and still see a big difference, that difference is less likely to be caused by the sample being unrepresentative.\n",
    "\n",
    "Note that if you asked 300,000 New Yorkers and 300,000 Kansans, the result would likely be statistically significant even if the difference between the group was only a penny. The t-test’s effect size complements its statistical significance, describing the magnitude of the difference, whether or not the difference is statistically significant.\n",
    "\n",
    "**Statistical Significance:** A statistically significant t-test result is one in which a difference between two groups is unlikely to have occurred because the sample happened to be atypical. **Statistical significance is determined by the size of the difference between the group averages, the sample size, and the standard deviations of the groups.** For practical purposes statistical significance suggests that the two larger populations from which we sample are “actually” different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Z-test\n",
    "\n",
    "Like a t-test but when you know the population variance. The standard error is $\\sigma/\\sqrt{N}$ and you just look up in a Z-score table the probability of getting that value or a more extremal one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Z-test versus t-test\n",
    "\n",
    "Often you don't know the standard deviation of the population, so you approximate the population standard deviation with that of the sample standard deviation. **This is roughly ok if sample size is > 30**. If $N_s > 30$, then the approximate test statistic is approximately normally distributed and a Z-test works ok. \n",
    "\n",
    "If $N_s < 30$ then the test statistic is **not** normally distributed and follows the t-distribution. In that case, you should the pdf of the t-distribution.\n",
    "\n",
    "The process is the same for both:\n",
    "- Step 1: Compute \n",
    "\\begin{align}\n",
    "\\text{test statistic} = \\frac{\\bar{x}-\\mu_x}{\\text{std error}} = \\frac{\\bar{x} - \\mu_x}{\\sigma_\\bar{x}/\\sqrt{N}}\n",
    "\\end{align}\n",
    "- Step 2: Look at size of $N_s$. \n",
    "    - If $N_s > 30$, use a Z-table to calculated p-value.\n",
    "    - If $N_s < 30$, use a t-table to calculated p-value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 95% Confidence Level\n",
    "\n",
    "The frequentist interpretation of a confidence level is that if you were to repeat the experiment many more times, 95% of the times you would get a result for that observable within the 95% C.L range.\n",
    "\n",
    "A simple way to compute the C.L. is to multiply the standard error by the 95% boundaries of the CDF of the statistic being used:\n",
    "\n",
    "- For a Z-test: two-tailed 95% means 0.025 integrals on either side, and z-scores of +-1.96. The 95% C.L. is then:\n",
    "\\begin{align}\n",
    "-1.96 &< \\frac{\\bar{x} - \\mu_x}{\\text{std. error}} < 1.96 \\\\\n",
    "x_{95}^{up} &= \\mu_x + \\text{std. error}*1.96 \\\\\n",
    "x_{95}^{down} &= \\mu_x - \\text{std. error}*1.96\n",
    "\\end{align}\n",
    "\n",
    "- For a t-test: the boundaries vary depending on the degrees of freedom (which is usually $N_{s}-1$). For $N_s = 10$, the boundaries are 2.262 and\n",
    "\\begin{align}\n",
    "-2.262 &< \\frac{\\bar{x} - \\mu_x}{\\text{std. error}} < 2.262 \\\\\n",
    "x_{95}^{up} &= \\mu_x + \\text{std. error}*2.262 \\\\\n",
    "x_{95}^{down} &= \\mu_x - \\text{std. error}*2.262\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variance of differences of random variables\n",
    "\n",
    "Let E(X) be the expected value of X. Remember that E(X+Y) = E(X) + E(Y) and E(X-Y) = E(X) - E(Y). However, what is the variance of X + Y?\n",
    "\n",
    "\\begin{align}\n",
    "\\mu_Z &= \\mu_X + \\mu_Y \\\\\n",
    "\\sigma^2_Z &= \\sigma^2_{X+Y} = \\sigma^2_X + \\sigma^2_Y \\\\\n",
    "\\end{align}\n",
    "\n",
    "What about X-Y?\n",
    "\\begin{align}\n",
    "\\sigma^2_Z &= \\sigma^2_{X-Y} \\\\\n",
    "           &= \\sigma^2_X + \\sigma^2_{-Y} \\\\\n",
    "\\end{align}\n",
    "\n",
    "But \n",
    "\\begin{align}\n",
    "\\sigma^2_{-Y} &= E[(-Y - E(-Y))^2] \\\\\n",
    "              &= E[(-1)^2*(Y + E(-Y))^2) \\\\\n",
    "              &= E[(Y - E(Y))^2] \\\\\n",
    "              &= \\sigma^2_Y\n",
    "\\end{align}\n",
    "\n",
    "Thus, we have finally that\n",
    "\\begin{align}\n",
    "\\sigma^2_{X-Y} &= \\sigma^2_X + \\sigma^2_{Y} \\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Difference of sample means distribution\n",
    "\n",
    "Let's assume you have two samples taken from two populations X and Y. Let $\\bar{x}$ and $\\bar{y}$ be the sample means and  $\\mu_{\\bar{X}}$ and $\\mu_{\\bar{Y}}$ the means of the sampling distributions of $\\bar{x}$ and $\\bar{y}$.\n",
    "\n",
    "How to compute statistical significance for the difference of the means of these two samples?\n",
    "\n",
    "Well, let's write it out:\n",
    "\\begin{align}\n",
    "\\bar{z} &= \\bar{x} - \\bar{y} \\\\\n",
    "\\mu_{\\bar{z}} &= \\mu_{\\bar{x}-\\bar{y}} = \\mu_{\\bar{x}} - \\mu_{\\bar{y}} \\\\\n",
    "\\sigma_{\\bar{z}} &= \\sigma_{\\bar{x}-\\bar{y}}\n",
    "\\end{align}\n",
    "\n",
    "From the result in the previous subsection, we have that\n",
    "\\begin{align}\n",
    "\\sigma^2_{\\bar{z}} &= \\sigma^2_{\\bar{x}-\\bar{y}} = \\sigma^2_{\\bar{x}} + \\sigma^2_{\\bar{y}} \\\\\n",
    "\\sigma_{\\bar{z}} &= \\sqrt{\\sigma^2_{\\bar{x}} + \\sigma^2_{\\bar{y}}} \\\\\n",
    "                 &= \\sqrt{\\frac{\\sigma^2_x}{N_x} + \\frac{\\sigma^2_y}{N_y}}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coefficient of determination, or $r^2$\n",
    "\n",
    "\\begin{align}\n",
    "r^2 &= 1 - \\frac{\\text{squared error of line}}{\\text{squared error of } y_i} \\\\\n",
    "    &= 1 - \\frac{\\sum (y_i - \\hat{y}_i)^2}{\\sum (y_i - \\mu_y)^2} \\\\\n",
    "    &= 1 - \\frac{\\sum (y_i - (mx_i+b))^2}{\\sum (y_i - \\mu_y)^2}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to tell if the difference in two regressed lines is significant?\n",
    "\n",
    "A Z-test for correlation coefficient is \n",
    "\n",
    "\\begin{align}\n",
    "Z_i = \\frac{1}{2}  \\log \\big(\\frac{1 + r_i}{1 - r_i}\\big),\n",
    "\\end{align}\n",
    "\n",
    "where $r = b\\frac{S_x}{S_y}$. The mean for $Z_1$ is given by\n",
    "\n",
    "\\begin{align}\n",
    "μ_{Z_1} = \\frac{1}{2} \\log \\big(\\frac{1 + ρ1}{1 - ρ1}\\big),\n",
    "\\end{align}\n",
    "\n",
    "where ρ or (rho) is the population correlation coefficient given by:\n",
    "\\begin{align}\n",
    "ρ_{x,y} = Cov(X,Y) / \\sigma_x \\sigma_y\n",
    "\\end{align}\n",
    "\n",
    "If you have two lines that were fit (at two different times), then your test statistic is\n",
    "\\begin{align}\n",
    "Z = \\frac{ (Z_1 - Z_2) - (μ_{Z_1} - μ_{Z_2}) } {\\sigma}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing population proportions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If I have two Bernoulli distributions 1 and 2, with probability for positive outcome $p_1$ and $p_2$. How do we propoerly compare them and decide whether their difference is statistically significant? How can we find the 95% confidence interval for $p_1 - p_2$? Let's understand it via an exercise:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**: Let's say we have 2 group, one of men and one of women, and we ask them if they will vote for a certain candidate or not (with 2 outcomes, 0 or 1). \n",
    "\n",
    "For group 1, 642 mean say they will vote for the candidate, while for group 2 591 women say they will vote for the candidate. Since the sample size is large, we can approximate $p_1$ and $p_2$ by the sample proportions. Thus, we have:\n",
    "\n",
    "\\begin{align}\n",
    "p_1 &= 0.642 \\\\\n",
    "\\sigma_1 &= \\sqrt{0.641*(1-0.641)} = 0.480 \\\\\n",
    "\\sigma_{\\bar{p}_1} &= 0.480 / 1000 \\\\\n",
    "p_1 &= 0.591 \\\\\n",
    "\\sigma_1 &= \\sqrt{0.591*(1-0.591)} = 0.492 \\\\\n",
    "\\sigma_{\\bar{p}_2} &= 0.492 / 1000\n",
    "\\end{align}\n",
    "\n",
    "Continuing:\n",
    "\n",
    "\\begin{align}\n",
    "\\sigma^2_{\\bar{p}_1 - \\bar{p}_2} &= \\sigma^2_{\\bar{p}_1} + \\sigma^2_{\\bar{p}_2} \\\\\n",
    "\\sigma_{\\bar{p}_1 - \\bar{p}_2} &\\approx 0.022\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our measure difference was 0.642 - 0.591 = 0.051 so our test statistic is:\n",
    "\n",
    "\\begin{align}\n",
    "ts = \\frac{0.051}{0.022} = 2.31\n",
    "\\end{align}\n",
    " \n",
    "which is greater than 1.96, so the result should be significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\chi^2$ distribution and fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The $\\chi^2$ distribution is the distribution of the sum of $N$ independent, normally distributed variables. For example, let's say you have 3 populations with a normal distribution. The probability distribution of the values for $x_1^2 + x_2^2 + x_3^2$ is given by the $\\chi^2$ distribution with 3 d.o.f.\n",
    "\n",
    "\\begin{align}\n",
    "\\chi^2(\\text{dof}=3) = \\text{PDF}(x_1^2 + x_2^2 + x_3^2)\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANOVA: one-way analysis of variance \n",
    "\n",
    "Used to determine whether there are any statistically significant differences between the means of three or more independent (unrelated) groups.\n",
    "\n",
    "**The one-way ANOVA compares the means between the groups you are interested in and determines whether any of those means are statistically significantly different from each other.** Specifically, it tests the null hypothesis:\n",
    "\n",
    "<br><center>\n",
    "$\n",
    "H_0: \\mu_1=\\mu_2 = \\mu_3 = ... = \\mu_k\n",
    "$\n",
    "</center>\n",
    "\n",
    "where $\\mu$ = group mean and k = number of groups. If, however, the one-way ANOVA returns a statistically significant result, we accept the alternative hypothesis (HA), which is that there are at least two group means that are statistically significantly different from each other.\n",
    "\n",
    "**The test that is associated with ANOVA is the Fisher test or F-test**. The F-test is defined as:\n",
    "\n",
    "\\begin{align}\n",
    "\\text{F-statistic} &= \\frac {\\text{sum of variation between groups / ndof of groups} } \n",
    "           {\\text {sum of variation within group / ndof of that group} } \\\\\n",
    "\\text{F-statistic} &= \\frac{ \\frac{SSB}{m-1} } { \\frac{SSW}{m(n-1)} }\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to read an F-statistic table\n",
    "\n",
    "The top (df1) is the numerator dof, the left axis is the denominator. Mnemonic is numerator dof is top df in table.\n",
    "\n",
    "**Example**: If you have 3 groups with 3 people in each, then (df1, df2) = (2, 6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**At this point, it is important to realize that the one-way ANOVA is an omnibus test statistic and cannot tell you which specific groups were statistically significantly different from each other, only that at least two groups were.** To determine which specific groups differed from each other, you need to use a post hoc test. \n",
    "\n",
    "If the ANOVA test gives p-value greater than $\\alpha$ (usually defined initially to be ~0.05), no need to follow-up. In other words, ANOVA does not show with confidence that the groups were different.\n",
    "\n",
    "However, if ANOVA gives a p-value < $\\alpha$, you have shown a statistically significant difference between two or more of the means, so do a *post-hoc* test. What are post hoc tests? ANOVA does not tell you which specific groups differed – post hoc tests do. Post hoc tests attempt to control the experimentwise error rate (usually alpha = 0.05) in the same manner that the one-way ANOVA is used instead of multiple t-tests. **You should only run one post hoc test – do not run multiple post hoc tests.** For a one-way ANOVA, you will probably find that just two tests need to be considered. If your data met the assumption of homogeneity of variances, use Tukey's honestly significant difference (HSD) post hoc test. **Tukey's HSD test is essentially a t-test**.\n",
    "\n",
    "### **Why not compare groups with multiple t-tests?**\n",
    "\n",
    "**Every time you conduct a t-test there is a chance that you will make a Type I error. This error is usually 5%. By running two t-tests on the same data you will have increased your chance of \"making a mistake\"** to 10%. The formula for determining the new error rate for multiple t-tests is not as simple as multiplying 5% by the number of tests. However, if you are only making a few multiple comparisons, the results are very similar if you do. As such, **three t-tests would be 15% (actually, 14.3%) and so on. These are unacceptable errors. An ANOVA controls for these errors so that the Type I error remains at 5% and you can be more confident that any statistically significant result you find is not just from running lots of tests.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permutations and combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A/B Testing\n",
    "\n",
    "Used when you want to decide whether to change something about your product, UI, website, etc... \n",
    "\n",
    "Compares group $A$, the control (or baseline, or current version), with a new version $B$ (version 2.0, different shade of blue, different ranking...) and checks whether there was a *significant* effect.\n",
    "\n",
    "- When running an A/B test, there will usually be an initial revulsion to the change, but non-control users will adapt to new version and you care about this **plateau'd experience**.\n",
    "- A/B testing is good to climb to the top of the mountain you're on, not to find out if there are other taller mountains.\n",
    "\n",
    "Example scenarios:\n",
    "- A/B testing can't tell you if you're missing something\n",
    "- A/B testing struggles to find effects that occur very rarely or spread out in time (referrals for apartment rentals). You need to run experiment for a long time, and in that time there's a chance you'll have to control for other factors.\n",
    "- Changing a company logo is too significant a change, long-term impact needs to be evaluated more carefully than through a short-term A/B test\n",
    "- Offering a premium service is hard to A/B test because you have to offer the service for free to define group B which bypasses the critical investigation of likelihood of paying for group B. You can define useful A/B tests but it's in general a more complex problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Power Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[This page](https://stats.idre.ucla.edu/other/mult-pkg/seminars/intro-power/) has a good intro to power analysis. Key points below:\n",
    "\n",
    "**First, what is Power? Answer: Power is the probability of detecting an effect, given that the effect is really there.** \n",
    "\n",
    "In other words, it is the probability of rejecting the null hypothesis when it is in fact false.  For example, let’s say that we have a simple study with drug A and a placebo group, and that the drug truly is effective; **the power is the probability of finding a difference between the two groups.**  So, imagine that we had a power of .8 and that this simple study was conducted many times.  **Having power of .8 means that 80% of the time, we would get a statistically significant difference between the drug A and placebo groups if the drug at truth-level indeed had an effect**.  This also means that 20% of the times that we run this experiment, we will not obtain a statistically significant effect between the two groups, even though there really is an effect in reality.\n",
    "\n",
    "**There are several of reasons why one might do a power analysis. Perhaps the most common use is to determine the necessary number of subjects needed to detect an effect of a given size.  Note that trying to find the absolute, bare minimum number of subjects needed in the study is often not a good idea.**  Additionally, power analysis can be used to determine power, given an effect size and the number of subjects available.  You might do this when you know, for example, that only 75 subjects are available (or that you only have the budget for 75 subjects), and you want to know if you will have enough power to justify actually doing the study.  **In most cases, there is really no point to conducting a study that is seriously underpowered.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There are 4 key parameters: power, effect size, sample size and alpha\n",
    "When discussing statistical power, we have four inter-related concepts: power, effect size, sample size and alpha.  These four things are related such that each is a function of the other three.  In other words, **if three of these values are fixed, the fourth is completely determined** (Cohen, 1988, page 14).  We mention this because, by increasing one, you can decrease (or increase) another.  **For example, if you can increase your effect size, you will need fewer subjects, given the same power and alpha level.  Specifically, increasing the effect size, the sample size and/or alpha will increase your power.**\n",
    "\n",
    "A power analysis is the union of substantive knowledge (i.e., knowledge about the subject matter), experimental or quasi-experimental design issues, and statistical analysis.  Almost every aspect of the experimental design can affect power.\n",
    "\n",
    "The graph below is nice because it shows diminishing returns after a certain point, which is relevant because increasing sample size comes at a financial cost.\n",
    "\n",
    "![Example_ttest](img/powergraph.gif)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average Treatment Effects (ATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 1\n",
    "A neurologist is testing the effect of a drug on response time by injecting 100 rats with a unit dose of the drug, then subjecting each to neurological stimulus and finally measuring the response time. The neurologist knows that the mean response time for rats not injected with the drug is 1.2 seconds. The mean of the 100 injected rats is 1.05 seconds with a sample standard deviation of 0.5 seconds. Do you think the drug has an effect on response time?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** Difference in mean is 0.15 seconds. I can approximate the population standard deviation with that of the sample, since the sample size if pretty decent (should be correct to within 1%). The z-statistic is then\n",
    "\n",
    "\\begin{align}\n",
    "Z &= \\frac{\\mu_s - \\mu_p}{\\text{std. error}} \\\\\n",
    "Z &= \\frac{\\mu_s - \\mu_p}{\\sigma/\\sqrt{N_s}} \\\\\n",
    "Z &= \\frac{0.15}{0.05} = 3 \\\\\n",
    "\\end{align}\n",
    "\n",
    "p-value = .0027. Significant if $\\alpha$ was 0.05 and test two-tailed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 2\n",
    "\n",
    "The mean emissions of all engines of a new design needs to be below 20 ppm if the design is to meet new emission requirements. Ten engines are manufactured for testing purposes, and the emission level of each is determined. The emission data is\n",
    "\n",
    "E = [15.6, 16.2, 22.5, 20.5, 16.4, 16.6, 17.9, 12.7, 13.9]\n",
    "\n",
    "$\\bar{x} = 17.17, s = 2.98$\n",
    "\n",
    "For an $\\alpha=0.01$, is the data sufficient to conclude that this type of engine meets the new standard?\n",
    "\n",
    "**Answer**: Let's choose the null hypothesis to be that the engine meets the new standard, while the alternative hypo is that it doesn't ($\\mu_x >=20$) which is one-tailed. The sample size is 10, so we should not use a Z-statistic. This is a t-test problem. The test statistic is\n",
    "\n",
    "\\begin{align}\n",
    "\\text{test-stat} &= \\frac{\\bar{x} - \\mu_x}{\\sigma/\\sqrt{N_\\text{sample}}} \\\\\n",
    "\\text{test-stat} &= \\frac{17.17 - 20}{2.98/\\sqrt{10}} = 2.83/0.94235874273 = 3.00 \\\\\n",
    "\\end{align}\n",
    "\n",
    "On a t-table with 9 dof, a one-tailed significance of 0.001 is 2.821 so we see the result is statistically significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 3\n",
    "\n",
    "We want to test the hypothesis that more than 30% of U.S. households have Internet access (with a significance level of 5%). We collect a sample of 150 households and find that 57 have access. \n",
    "\n",
    "**Answer**: \n",
    "- Null hypothesis is that $\\leq$ 30% of households have Internet\n",
    "- Alternative hypothesis is that $>$ 30% of households have Internet\n",
    "\n",
    "We will answer the question by answering the following: If 30% of households have internet, how likely were we to sample 57 out of 150?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "\\text{test stat} = \\frac{0.38 - 0.\\bar{3}}{std error}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y = [0.7, 0.3]\n",
    "plt.bar(x=[0,1], height=Y, ); \n",
    "plt.xticks([0,1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of the population is a Bernoulli distribution with $\\mu_x = 0.3$ and $\\sigma = \\sqrt{pq} = \\sqrt{0.21}$\n",
    "\n",
    "Then\n",
    "\n",
    "\\begin{align}\n",
    "\\text{test stat} = \\frac{0.38 - 0.3}{\\sqrt{0.21}/\\sqrt{150}} = 2.14\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we know the variance of the population, we do a Z-test. The one-tailed Z-value for 95% is roughly 1.65, so the result is significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 4\n",
    "\n",
    "We're trying to test if a new, low-fat diet actually helps obese people lose weight. 100 randomly assigned obese people are assigned to group 2 and put on a diet of approximately the same amount of food, but not as low in fat. After 4 months, the mean weight loss was 9.31 lbs for group 1 (s=4.67), and 7.40 for group 2 (s=4.04). \n",
    "\n",
    "**Answer**: this is just compairing two population means. \n",
    "\n",
    "- Null hypothesis = low-fat diet does not help\n",
    "- Alternative hypothesis = low-fat diet does help\n",
    "\n",
    "The test statistic is:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "ts &= \\frac{\\mu_1 - \\mu_2}{s_1 + s2} = \\frac{1.91}{\\sqrt{4.67^2/100 + 4.04^2/100}} \\\\\n",
    "ts &= \\frac{1.91}{\\sqrt{21.81/100 + 16.32/100}} = \\frac{1.91}{0.617} \\approx 2.85\n",
    "\\end{align}\n",
    "\n",
    "So the result is significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 5\n",
    "\n",
    "You're an investor and you ask the current owner of a restaurant what is the expected number of customers of a restaurant in each day of the week. The owner tells you:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "expected_diners (in % of total) = {'M':10, 'T':10, 'W':15, 'Th':20, 'F':30, 'S':15}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But when you do your own observations on a given week, you see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_diners = {'M':30, 'T':14, 'W':34, 'Th':45, 'F':57, 'S':20}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are the results compatible ($\\alpha=0.05$)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**: \n",
    "- Null hypothesis: the owner's distribution is correct\n",
    "- Alternative hypothesis: the owner's distribution is not representative\n",
    "\n",
    "The total observed was 200. The expected observed number of diners are then"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = [20, 20, 30, 40, 60, 30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "\\text{test statistic} = \\chi^2 \\text{statistic} = \\sum \\frac{(\\text{obs - exp})^2 } { \\text{exp}}\n",
    "\\end{align}\n",
    "\n",
    "which is 11.44 for our distribution. Is this a more extreme result of the critical $\\chi^2$ value.\n",
    "\n",
    "**We have 5 dof, not 6, because computing the expected value eats one dof**. The $\\chi^2(\\text{dof}=5)_{\\text{critical}} = 11.07$, so our result is significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
